{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import date\n",
    "import colorsys\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class Series:\n",
    "    def __init__(self, series_id):\n",
    "        self.series_id = series_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anime or manga\n",
    "is_anime = True\n",
    "\n",
    "# Map parameters\n",
    "if is_anime:\n",
    "    threshold = 3 # 3 ideal for anime\n",
    "else: \n",
    "    threshold = 2 # 2 ideal for manga\n",
    "\n",
    "# Api parameters\n",
    "api_attempts = 10\n",
    "request_delay = 1\n",
    "retry_delay = 60\n",
    "\n",
    "# Initialization\n",
    "queue = []\n",
    "edge_list = []\n",
    "series_list = {}\n",
    "genre_list = {}\n",
    "is_first_run = True\n",
    "current_id = -1\n",
    "\n",
    "export_csvs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommendation data, takes ~2-3 hours\n",
    " \n",
    "if is_anime:\n",
    "    api_address = \"https://api.jikan.moe/v4/anime/\"\n",
    "else: \n",
    "    api_address = \"https://api.jikan.moe/v4/manga/\"\n",
    "    \n",
    "if is_first_run:\n",
    "    queue.append(1) # Bebop(anime)/Monster(manga)\n",
    "    is_first_run = False\n",
    "else:\n",
    "    queue.insert(0, current_id) # Run if connection cuts out\n",
    "\n",
    "while len(queue) > 0:\n",
    "    current_id = queue.pop(0)\n",
    "    series = Series(current_id)\n",
    "    \n",
    "    # Get data\n",
    "    endpoint = api_address + str(series.series_id) + \"/\"\n",
    "    rec_endpoint = api_address + str(series.series_id) + \"/recommendations\"\n",
    "    \n",
    "    for attempt in range(api_attempts):\n",
    "        try:\n",
    "            series_data_json = requests.get(endpoint).json()\n",
    "            series_data = series_data_json[\"data\"]\n",
    "            time.sleep(request_delay) # Wait for cached requests\n",
    "            rec_data_json = requests.get(rec_endpoint).json()\n",
    "            rec_data = rec_data_json[\"data\"]\n",
    "            time.sleep(request_delay) \n",
    "            api_success = True\n",
    "        except:\n",
    "            print(\"Retrying...\")\n",
    "            time.sleep(retry_delay)\n",
    "            api_success = False\n",
    "            continue\n",
    "        break\n",
    "    \n",
    "    if not api_success:\n",
    "        break\n",
    "\n",
    "    # Stuff on the map\n",
    "    series.name = series_data['title']\n",
    "    series.img_url = series_data['images']['jpg']['image_url']\n",
    "    \n",
    "    # Stuff to include in search\n",
    "    series.eng_name = series_data['title_english']\n",
    "    series.jp_name = series_data['title_japanese']\n",
    "    series.alt_names = series_data['title_synonyms']\n",
    "    \n",
    "    # Stuff to filter for\n",
    "    series.type = series_data['type']\n",
    "    series.score = series_data['score']\n",
    "    series.members = series_data['members']\n",
    "    series.rank = series_data['rank']\n",
    "    series.popularity = series_data['popularity']\n",
    "    series.favorites = series_data['favorites']\n",
    "    \n",
    "    # Extra stuff\n",
    "    series.url = series_data['url']\n",
    "    # series.synopsis = series_data['synopsis']\n",
    "    \n",
    "    # Anime/manga specific fields\n",
    "    if is_anime:\n",
    "        series.season = series_data['season']\n",
    "        series.year = series_data['year']\n",
    "        series.episodes = series_data['episodes']\n",
    "        series.start_year = series_data['aired']['prop']['from']['year']\n",
    "    else:\n",
    "        series.chapters = series_data['chapters']\n",
    "        series.volumes = series_data['volumes']\n",
    "        series.start_year= series_data['published']['prop']['from']['year']\n",
    "    \n",
    "    # Genres\n",
    "    series.genres = {}\n",
    "    for genre in series_data['genres'] + series_data['explicit_genres'] + series_data['themes'] + series_data['demographics']:\n",
    "        genre_id = genre['mal_id']\n",
    "        genre_name = genre['name']\n",
    "        series.genres[genre_id] = genre_name;\n",
    "        if genre_id not in genre_list:\n",
    "            genre_list[genre_id] = genre_name\n",
    "\n",
    "    # Recommendations\n",
    "    series.recs = {}\n",
    "    for rec in rec_data:\n",
    "        rec_id = rec['entry']['mal_id']\n",
    "        rec_count = rec['votes']\n",
    "        if rec_count < threshold:\n",
    "            continue\n",
    "        series.recs[rec_id] = rec_count\n",
    "    \n",
    "    # Add anime to visited dictionary, new anime to queue, new edges to edge list\n",
    "    series_list[series.series_id] = series\n",
    "    \n",
    "    for rec_id in series.recs:\n",
    "        if rec_id not in series_list:\n",
    "            if rec_id not in queue:\n",
    "                queue.append(rec_id)\n",
    "            edge_list.append([series.series_id, rec_id, series.recs[rec_id]])\n",
    "    \n",
    "    clear_output()\n",
    "    print(series.name + ' | ' + str(len(queue)))    \n",
    "\n",
    "data_date = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_anime:\n",
    "    pickle.dump(series_list, open('dumps/dump_series.p', 'wb'))\n",
    "    pickle.dump(edge_list, open('dumps/dump_edges.p', 'wb'))\n",
    "    pickle.dump(genre_list, open('dumps/dump_genres.p', 'wb'))\n",
    "else:\n",
    "    pickle.dump(series_list, open('dumps/dump_manga_series.p', 'wb'))\n",
    "    pickle.dump(edge_list, open('dumps/dump_manga_edges.p', 'wb'))\n",
    "    pickle.dump(genre_list, open('dumps/dump_manga_genres.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_anime:\n",
    "    series_list = pickle.load(open('dumps/dump_series.p', 'rb'))\n",
    "    edge_list = pickle.load(open('dumps/dump_edges.p', 'rb'))\n",
    "    genre_list = pickle.load(open('dumps/dump_genres.p', 'rb'))\n",
    "else:\n",
    "    series_list = pickle.load(open('dumps/dump_manga_series.p', 'rb'))\n",
    "    edge_list = pickle.load(open('dumps/dump_manga_edges.p', 'rb'))\n",
    "    genre_list = pickle.load(open('dumps/dump_manga_genres.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data: \" + str(len(series_list)) + \" series, \" + \n",
    "                 str(len(edge_list)) + \" edges, \" + \n",
    "                 str(len(genre_list)) + \" genres\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate communities\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(series_list)\n",
    "G.add_weighted_edges_from(edge_list)\n",
    "\n",
    "seed = 69\n",
    "\n",
    "# Detect communities using louvain method\n",
    "communities = community.louvain_communities(G, seed=seed)\n",
    "print(\"Generated \" + str(len(communities)) + \" communities\")\n",
    "\n",
    "# Generate positions\n",
    "pos = nx.circular_layout(G)\n",
    "positions = nx.spring_layout(G, k=1, iterations=5000, scale=10000, pos=pos, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate colors\n",
    "n = len(communities)\n",
    "hls_tuples = [(x*1.0/n, 0.8, 0.8) for x in range(n)]\n",
    "rgb_tuples = [colorsys.hls_to_rgb(*hls) for hls in hls_tuples]\n",
    "hex_colors = ['#%02x%02x%02x' % tuple(int(x*255) for x in rgb) for rgb in rgb_tuples]\n",
    "sns.palplot(hex_colors)\n",
    "print(hex_colors)\n",
    "\n",
    "# Set community and color\n",
    "for idx, node_ids in enumerate(communities):\n",
    "    for n in node_ids:\n",
    "        series_list[n].community = idx\n",
    "        series_list[n].color = hex_colors[idx]\n",
    "\n",
    "\n",
    "# Generate modified positions\n",
    "modified_positions = positions\n",
    "if is_anime:\n",
    "    # To keep the map fairly consistent, going to have Code Geass in top left, K-On in bottom right, and Haikyuu in top right\n",
    "    code_geass = 1575\n",
    "    k_on = 5680\n",
    "    haikyuu = 20583\n",
    "\n",
    "    # shift the graph so that it is centered at Code Geass and K-On\n",
    "    modified_positions = { k:([v[0] - modified_positions[code_geass][0] , \n",
    "                               v[1] - modified_positions[code_geass][1]]) \n",
    "                           for (k, v) in modified_positions.items() }\n",
    "\n",
    "    # shift Code Geass to the origin\n",
    "    kon_angle = math.atan2(modified_positions[k_on][1], modified_positions[k_on][0])\n",
    "\n",
    "    # rotate graph so that Code Geass is horizontal to K-On, with Code Geass on the left\n",
    "    r_angle = -kon_angle\n",
    "    modified_positions = { k:([v[0]*math.cos(r_angle) - v[1]*math.sin(r_angle), \n",
    "                               v[0]*math.sin(r_angle) + v[1]*math.cos(r_angle)]) \n",
    "                           for (k, v) in modified_positions.items() }\n",
    "\n",
    "\n",
    "    # flip graph if Haikyuu is below Code Geass\n",
    "    if (modified_positions[haikyuu][1] < modified_positions[code_geass][1]):   \n",
    "        modified_positions = { k:([v[0] , -v[1]]) for (k, v) in modified_positions.items() }\n",
    "\n",
    "    # rotate graph -45 degrees\n",
    "    r_angle2 = math.radians(-45) \n",
    "    modified_positions = { k:([v[0]*math.cos(r_angle2) - v[1]*math.sin(r_angle2), \n",
    "                               v[0]*math.sin(r_angle2) + v[1]*math.cos(r_angle2)]) \n",
    "                           for (k, v) in modified_positions.items() }\n",
    "\n",
    "    # shift the graph to the midpoint between Code Geass and K-On\n",
    "    modified_positions = { k:([v[0] - modified_positions[k_on][0]/2 , \n",
    "                               v[1] - modified_positions[k_on][1]/2]) \n",
    "                           for (k, v) in modified_positions.items() }\n",
    "\n",
    "    # flip graph since sigma flips y axis\n",
    "    modified_positions = { k:([v[0] , -v[1]]) for (k, v) in modified_positions.items() }\n",
    "    \n",
    "    print(\"Code Geass: \" + str(modified_positions[code_geass][0]) + \", \" + str(modified_positions[code_geass][1]) + \n",
    "          \" | K-ON: \" + str(modified_positions[k_on][0]) + \", \" + str(modified_positions[k_on][1]) +\n",
    "          \" | Haikyuu: \" + str(modified_positions[haikyuu][0]) + \", \" + str(modified_positions[haikyuu][1]))\n",
    "\n",
    "# assign positions\n",
    "for series in series_list.values():\n",
    "    series.xpos = modified_positions[series.series_id][0]\n",
    "    series.ypos = modified_positions[series.series_id][1]\n",
    "    series.weighted_degree = G.degree(series.series_id, 'weight')\n",
    "\n",
    "# assign node sizes\n",
    "# We scale nodes logarithmically, then scale again to the max value\n",
    "max_weighted_degree = max([s.weighted_degree for s in series_list.values()])\n",
    "for series in series_list.values():\n",
    "    series.size = math.log(series.weighted_degree) / math.log(max_weighted_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = {}\n",
    "\n",
    "sig_figs = 6\n",
    "img_base_url = 'https://cdn.myanimelist.net/images/'\n",
    "link_base_url = 'https://myanimelist.net/'\n",
    "\n",
    "elements['nodes'] = []\n",
    "for series in series_list.values():\n",
    "    node = {}\n",
    "    node['id'] = series.series_id\n",
    "    node['name'] = series.name\n",
    "    node['engName'] = series.eng_name\n",
    "    node['jpName'] = series.jp_name\n",
    "    node['altNames'] = series.alt_names\n",
    "    node['imgUrlPath'] = (series.img_url).replace(img_base_url, '')\n",
    "    node['urlPath'] = (series.url).replace(link_base_url, '')\n",
    "    node['weightedDegree'] = series.weighted_degree\n",
    "    node['type'] = series.type\n",
    "    node['score'] = series.score\n",
    "    node['members'] = series.members\n",
    "    node['favorites'] = series.favorites\n",
    "    node['rank'] = series.rank\n",
    "    node['popularity'] = series.popularity\n",
    "    node['genres'] = list(series.genres.keys())\n",
    "    node['xPos'] = round(series.xpos, sig_figs)\n",
    "    node['yPos'] = round(series.ypos, sig_figs)\n",
    "    node['community'] = series.community\n",
    "    node['color'] = series.color\n",
    "    node['size'] = round(series.size, sig_figs)\n",
    "    node['startYear'] = series.start_year\n",
    "    \n",
    "    if is_anime:\n",
    "        node['season'] = series.season\n",
    "        node['year'] = series.year\n",
    "        node['episodes'] = series.episodes\n",
    "    else:\n",
    "        node['chapters'] = series.chapters\n",
    "        node['volumes'] = series.volumes\n",
    "    \n",
    "    elements['nodes'].append(node)\n",
    "\n",
    "elements['edges'] = []\n",
    "max_edge_weight = max([e[2] for e in edge_list])\n",
    "for edge in edge_list:\n",
    "    e = {}\n",
    "    e['id'] = str(edge[0])+\"-\"+str(edge[1])\n",
    "    e['source'] = edge[0]\n",
    "    e['target'] = edge[1]\n",
    "    e['weight'] = edge[2]\n",
    "    e['size'] = round(math.log(edge[2]) / math.log(max_edge_weight), sig_figs)\n",
    "    \n",
    "    elements['edges'].append(e)\n",
    "\n",
    "elements['genres'] = []\n",
    "for (k, v) in genre_list.items():\n",
    "    g = {}\n",
    "    g['id'] = k\n",
    "    g['name'] = v\n",
    "\n",
    "    elements['genres'].append(g)\n",
    "\n",
    "m = {}\n",
    "m['lastUpdated'] = data_date.strftime(\"%B %d, %Y\")\n",
    "m['imgBaseUrl'] = img_base_url\n",
    "m['linkBaseUrl'] = link_base_url\n",
    "elements['metadata'] = m\n",
    "\n",
    "if is_anime:\n",
    "    with open('data/anime_data.json', 'w', encoding='utf8') as json_file:\n",
    "        json.dump(elements, json_file, ensure_ascii=False)\n",
    "else:\n",
    "    with open('data/manga_data.json', 'w', encoding='utf8') as json_file:\n",
    "        json.dump(elements, json_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate .csv files for import into Gephi\n",
    "if export_csvs:\n",
    "    # Export edges\n",
    "    with open('dumps/edges.csv', 'w', encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"Source\", \"Target\", \"Weight\", \"Type\"])\n",
    "        for e in edge_list:\n",
    "            line = list(e)\n",
    "            line.append(\"Undirected\")\n",
    "            writer.writerow(line)\n",
    "\n",
    "    # Export nodes\n",
    "    with open('dumps/nodes.csv', 'w', encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"ID\", \"Label\", \"Image\", \"Community\"])\n",
    "        for a in series_list.values():\n",
    "            writer.writerow([a.series_id, a.name, a.img_url, a.community])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
